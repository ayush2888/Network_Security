# ğŸš€ Phishing URL Detection (Network Security Project)

This project is a **Machine Learning application** for detecting **phishing URLs**.  
It uses a pipeline-based architecture for data ingestion, preprocessing, model training, evaluation, and deployment.  

The app provides a **Flask-based web interface** to make predictions on URLs.  

# Overview

This project is a Machine Learning pipeline for detecting network security threats. It performs:
Data ingestion from MongoDB
Data validation (schema check, drift detection)
Data transformation (KNN imputation, preprocessing)
Model training (Random Forest, Decision Tree, Logistic Regression, etc.)
Model deployment via Flask web app

The pipeline saves trained models and preprocessor objects, which can be served for real-time predictions.

# Features

End-to-end ML pipeline for network security detection.
Automatically handles data ingestion, validation, transformation, and training.
Supports multiple classification models with hyperparameter tuning.
Model tracking with MLflow for experiment management.
Deployment-ready Flask app for predictions.

Compatible with AWS S3 sync for artifacts and trained models.

# Dataset Features

The model uses 30+ features that capture URL characteristics, domain properties, web page elements, and traffic metrics, including:

1) URL & Domain Features:
having_IP_Address, URL_Length, Shortining_Service, having_At_Symbol, double_slash_redirecting, Prefix_Suffix, having_Sub_Domain, SSLfinal_State, Domain_registeration_length

2) Web Page & Link Features:
Favicon, port, HTTPS_token, Request_URL, URL_of_Anchor, Links_in_tags, SFH, Submitting_to_email, Abnormal_URL, Redirect, on_mouseover, RightClick, popUpWidnow, Iframe

3) Domain & Traffic Metrics:
age_of_domain, DNSRecord, web_traffic, Page_Rank, Google_Index, Links_pointing_to_page

4) Statistical Report:
Statistical_report

5) The target column is:
class (1 = Legitimate, -1 = Phishing)

This comprehensive set of features allows the model to accurately classify phishing attempts based on structural, content-based, and behavioral characteristics of websites.

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ app.py                     # Flask app for serving predictions
â”œâ”€â”€ main.py                    # Script to run the complete training pipeline
â”œâ”€â”€ push_data.py               # Push local data to MongoDB
â”œâ”€â”€ test_mongo_db.py           # Test MongoDB connectivity
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup.py                   # Package setup
â”œâ”€â”€ Dockerfile                 # For containerization
â”œâ”€â”€ .github/workflows/main.yml # CI/CD pipeline (GitHub Actions)

â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ .gitignore                 # Git ignore rules

â”œâ”€â”€ templates/
â”‚   â””â”€â”€ table.html             # HTML template for displaying prediction results

â”œâ”€â”€ prediction_output/
â”‚   â””â”€â”€ output.csv             # Stores batch prediction results

â”œâ”€â”€ valid_data/
â”‚   â””â”€â”€ test.csv               # Example dataset for validation

â”œâ”€â”€ final_model/
â”‚   â”œâ”€â”€ model.pkl              # Trained ML model
â”‚   â””â”€â”€ preprocessor.pkl       # Preprocessing pipeline

â”œâ”€â”€ data_schema/
â”‚   â””â”€â”€ schema.yaml            # Schema definition for input data

â”œâ”€â”€ Network_Data/
â”‚   â””â”€â”€ Phising_Testing_Data.csv # Dataset for testing

â”œâ”€â”€ networksecurity/           # Main project package
â”‚   â”œâ”€â”€ components/            # Pipeline components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/              # Training & prediction pipelines
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”‚   â””â”€â”€ batch_prediction.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”‚   â”œâ”€â”€ main_utils/utils.py
â”‚   â”‚   â”œâ”€â”€ ml_utils/metric/classification_metric.py
â”‚   â”‚   â””â”€â”€ ml_utils/model/estimator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ cloud/                 # Cloud sync helpers (S3)
â”‚   â”‚   â””â”€â”€ s3_syncer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ entity/                # Entity & artifact definitions
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py
â”‚   â”‚   â””â”€â”€ config_entity.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logging/logger.py      # Centralized logging
â”‚   â”œâ”€â”€ exception/exception.py # Custom exception handling
â”‚   â””â”€â”€ constant/              # Project constants
â”‚       â””â”€â”€ training_pipeline/
â”‚           â””â”€â”€ __init__.py


---


## âš™ï¸ Installation & Setup

### ğŸ”¹ Local Development Setup

1. Clone the repo
   
   git clone https: https://github.com/ayush2888/Network_Security.git
   cd network-security

2. Create virtual environment

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

3. Install dependencies

pip install -r requirements.txt

4. Run the app

python app.py

---


# How to Run

1ï¸âƒ£ Run the ML Training Pipeline
This will ingest data, validate it, transform it, train multiple models, and save the best model.

python main.py

Artifacts will be saved in final_model/ and networksecurity/artifacts/.
MLflow logs are tracked automatically.

2ï¸âƒ£ Run the Flask Web App
This loads the trained model and preprocessor and serves a web interface for prediction.

python app.py

Open your browser at http://127.0.0.1:5000/
Upload input data or use the form to get predictions.

